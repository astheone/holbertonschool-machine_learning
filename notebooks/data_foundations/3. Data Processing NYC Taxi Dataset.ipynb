{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# ğŸ§  Data Processing & Planning â€” NYC Yellow Taxi Dataset (2019â€“2020)\n","### _Portfolio Project â€” Holberton School Machine Learning Track_\n","#### Author: **Alvi Sulaj**\n","\n","This notebook outlines the full data-processing plan for the NYC Yellow Taxi dataset, covering:\n","- data sources  \n","- formats  \n","- exploratory analysis strategy  \n","- hypotheses  \n","- handling missing values & outliers  \n","- feature engineering  \n","- dataset splitting  \n","- storage structure  \n","\n","This notebook serves as **Task 0: Planning**."]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## ğŸ” 1. Data Sources\n","\n","The primary dataset comes from the **NYC Taxi & Limousine Commission (TLC)**.\n","\n","Official dataset link:  \n","ğŸ”— https://www.nyc.gov/site/tlc/about/tlc-trip-record-data.page\n","\n","The dataset contains:\n","- pickup & dropoff timestamps  \n","- pickup & dropoff location IDs  \n","- trip distance  \n","- passenger count  \n","- fare details (fare, tips, tolls, total)  \n","- payment type  \n","- vendor information  \n","\n","These files are released monthly and contain millions of rows each.\n","\n","### ğŸ“¦ Additional (Optional) Data Sources\n","To enrich the analysis:\n","- **NOAA Weather Data** â†’ correlate weather with taxi demand  \n","- **NYC Borough Shapefiles** â†’ spatial mapping  \n","- **Holiday Calendar** â†’ detect seasonal spikes  "]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[{"data":{"text/plain":["['/site/tlc/businesses/yellow-cab.page',\n"," '/assets/tlc/downloads/pdf/data_dictionary_trip_records_yellow.pdf',\n"," 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2025-01.parquet',\n"," 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2025-02.parquet',\n"," 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2025-03.parquet',\n"," 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2025-04.parquet',\n"," 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2025-05.parquet',\n"," 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2025-06.parquet',\n"," 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2025-07.parquet',\n"," 'https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2025-08.parquet']"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["# Listing all available TLC monthly files (example)\n","import requests\n","from bs4 import BeautifulSoup\n","\n","url = \"https://www.nyc.gov/site/tlc/about/tlc-trip-record-data.page\"\n","response = requests.get(url)\n","soup = BeautifulSoup(response.text, \"html.parser\")\n","\n","links = [a['href'] for a in soup.find_all('a', href=True) if \"yellow\" in a['href']]\n","links[:10]  # show first 10"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["> ğŸ” Note:\n","> In a real project, we could automatically list all TLC CSV files using web-scraping tools.\n","> However, the Holberton environment does not support `BeautifulSoup` or external installations.\n","> For this project, we will reference the monthly Yellow Taxi CSV files manually."]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## ğŸ“„ 2. Current Data Format\n","\n","### Raw Format\n","- Multiple **CSV** files  \n","- Monthly structure (e.g., `yellow_tripdata_2019-01.csv`)\n","- Files are large (1Mâ€“7M rows per month)\n","\n","### Working Format\n","- Loaded into **Pandas DataFrames**\n","\n","### Preferred Export Format\n","- **Parquet** â†’ efficient storage, compressed, faster loading  \n","- **Feather** (optional)\n","- **CSV** (fallback compatibility)\n","\n","### Reason for Choosing Parquet\n","- 3â€“6x faster read/write  \n","- preserves schema  \n","- optimised for columnar analytics"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Sample file not found â€” this is expected in planning stage.\n"]}],"source":["import pandas as pd\n","\n","# Example structure for loading one monthly CSV (placeholder)\n","sample_path = \"/content/yellow_tripdata_2019-01.csv\"   # You will replace with your path\n","\n","try:\n","    df_sample = pd.read_csv(sample_path, nrows=5000)\n","    df_sample.head()\n","except FileNotFoundError:\n","    print(\"Sample file not found â€” this is expected in planning stage.\")"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## ğŸ§¬ 3. Existing Features in Dataset\n","\n","The dataset contains the following key fields:\n","\n","### ğŸš• Trip Metadata\n","- `tpep_pickup_datetime`\n","- `tpep_dropoff_datetime`\n","- `trip_distance`\n","- `passenger_count`\n","\n","### ğŸ“ Spatial Features\n","- `PULocationID` â†’ pickup zone  \n","- `DOLocationID` â†’ dropoff zone  \n","\n","### ğŸ’µ Economic Features\n","- `fare_amount`\n","- `tip_amount`\n","- `tolls_amount`\n","- `mta_tax`\n","- `total_amount`\n","\n","### ğŸ’³ Payment Information\n","- `payment_type`  \n","- `ratecodeID`  \n","- `vendorID`\n","\n","These features will be deeply explored in EDA."]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Data not loaded yet â€” placeholder cell.\n"]}],"source":["# Simulated structure to show how summary would be performed once data is loaded\n","try:\n","    df_sample.info()\n","except:\n","    print(\"Data not loaded yet â€” placeholder cell.\")"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## ğŸ“Š 4. Planned Exploratory Data Analysis (EDA)\n","\n","A structured EDA will analyze:\n","\n","### âœ” Missing Values\n","- Identify incomplete rows  \n","- Detect columns with high sparsity  \n","- Evaluate logical consistency  \n","\n","### âœ” Distributions\n","- Trip distance distribution  \n","- Fare distribution  \n","- Duration distribution  \n","\n","### âœ” Outliers\n","- Very short/long rides  \n","- Negative or impossible values  \n","- Abnormal fare-per-mile  \n","\n","### âœ” Temporal Behaviors\n","- Trips by hour of day  \n","- Weekday vs weekend  \n","- Monthly seasonality  \n","\n","### âœ” Geospatial Patterns\n","- Heatmaps of pickup zones  \n","- Flow analysis between boroughs  "]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## ğŸ§ª 5. Hypotheses and How They Will Be Tested\n","\n","### ğŸŸ  Hypothesis 1  \n","**Short trips have a higher fare-per-mile than long trips.**  \n","â†’ Test via grouping + comparing distributions.\n","\n","### ğŸŸ  Hypothesis 2  \n","**Taxi demand peaks during rush hours (8â€“10 AM, 4â€“7 PM).**  \n","â†’ Test via time-series counts.\n","\n","### ğŸŸ  Hypothesis 3  \n","**Rain increases taxi usage.**  \n","â†’ Merge with weather data + compare daily totals.\n","\n","### ğŸŸ  Hypothesis 4  \n","**Tip percentage increases at night.**  \n","â†’ Extract hour + analyze tip rates by time block."]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## âš ï¸ 6. Missing Data & Outlier Strategy\n","\n","### Missing Data\n","- Drop rows missing timestamps  \n","- Impute categorical fields if patterns allow  \n","- Handle fare missingness with domain rules  \n","\n","### Outliers\n","- Remove rides with:\n","  - distance == 0  \n","  - duration <= 1 minute  \n","  - fare <= 0  \n","  - speed > 120 mph  \n","\n","### Outlier detection techniques:\n","- Z-score threshold  \n","- IQR (Interquartile Range)  \n","- Logical domain constraints  "]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## ğŸ› ï¸ 7. Feature Engineering Plan\n","\n","New features will be created to improve model performance:\n","\n","### Time-based features\n","- pickup_hour  \n","- pickup_weekday  \n","- is_weekend  \n","- is_rush_hour  \n","\n","### Trip dynamics\n","- trip_duration (minutes)  \n","- speed (miles per hour)  \n","- fare_per_mile  \n","- tip_percentage  \n","\n","### Spatial enhancements\n","- borough_pickup  \n","- borough_dropoff  \n","- route_category (PU-DO combination)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## ğŸ§© 8. Dataset Splitting Strategy\n","\n","### Random Split\n","- 70% training  \n","- 15% validation  \n","- 15% testing  \n","\n","### Time-Series Split (preferred for this dataset)\n","- Training â†’ 2019  \n","- Validation â†’ Janâ€“Jun 2020  \n","- Test â†’ Julâ€“Dec 2020  "]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["## ğŸ—‚ï¸ 9. Storage Structure\n","\n","project/\n","â”œâ”€â”€ raw_data/\n","â”œâ”€â”€ processed_data/\n","â”œâ”€â”€ notebooks/\n","â”œâ”€â”€ src/\n","â”œâ”€â”€ env/\n","â””â”€â”€ README.md\n","\n","\n","### Cleaned datasets will be saved as:\n","- `processed_data/cleaned_2019_2020.parquet`\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["---\n","\n","# âœ… This completes the extended technical data plan.\n"]},{"cell_type":"markdown","metadata":{},"source":[]}],"metadata":{"kernelspec":{"display_name":"Holberton Python","language":"python","name":"holberton"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"}}},"nbformat":4,"nbformat_minor":2}
